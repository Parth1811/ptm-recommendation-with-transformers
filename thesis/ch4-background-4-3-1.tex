\subsection{PTM Repositories and Model Hubs}
\label{subsec:ptm-repositories}

The proliferation of pre-trained model hosting platforms has democratized access to deep learning resources but has simultaneously introduced significant challenges for model selection. The Hugging Face Hub~\cite{wolf2020huggingface}, one of the largest and most widely used PTM repositories, hosts hundreds of thousands of models with model cards that vary substantially in completeness, accuracy, and granularity of documentation~\cite{akter2024replication}. This inconsistency complicates systematic model discovery and evaluation, particularly for practitioners unfamiliar with specific model families or domains.

To support empirical analysis of PTM ecosystems, several datasets and studies have emerged. The HFCommunity dataset~\cite{hfcommunity2024dataset} provides structured snapshots of the Hugging Face Hub, capturing metadata, repository relationships, usage statistics, and temporal evolution patterns. PeaTMOSS~\cite{jiang2024peatmoss} analyzes pre-trained models as software artifacts, examining their distribution patterns, reuse practices, dependency structures, and maintenance characteristics across major repositories. PTMTorrent~\cite{ding2024ptmtorrent} aggregates PTM packages from multiple hosting platforms, enabling cross-hub comparative analysis and revealing substantial fragmentation in model documentation, versioning conventions, and metadata schemas. Collectively, these studies demonstrate that PTM selection operates within a heterogeneous, large-scale environment where metadata consistency cannot be assumed and manual curation remains infeasible at scale. This reality motivates the development of automated recommendation systems that can navigate incomplete or unreliable metadata through learned representations of model-dataset compatibility.
