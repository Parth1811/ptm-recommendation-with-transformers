[extractor]
output_stack_size = 8192
model_output_folder = /scratch/gilbreth/patil185/artifacts/extracted/models
default_extractor_class = HuggingFacePipelineExtractor
extractor_registry = {
    "Fashion-Mnist-SigLIP2": "SiglipExtractor",
    "Mnist-Digits-SigLIP2": "SiglipExtractor",
    "resnet34_svhn": "DetectorBasedExtractor",
    "densenet121_svhn": "DetectorBasedExtractor",
    "vgg16_bn_svhn": "DetectorBasedExtractor",
    "resnet34_cifar100": "DetectorBasedExtractor",
    "resnet18_cifar100": "DetectorBasedExtractor",
    }

[autoencoder]
; A single linear layer is often enough for very small datasets; add more depth for complex parameter spaces.
encoder_input_size = 8192
encoder_output_size = 256
decoder_output_size = 8192
encoder_hidden_layers = [1024, 512]
decoder_hidden_layers = [1024, 512]
use_activation = true

[train_model_autoencoder]
batch_size = 16
num_epochs = 10000
learning_rate = 0.001
shuffle = true
log_every_n_epochs = 10
extracted_models_dir = /scratch/gilbreth/patil185/artifacts/extracted/models
model_save_directory = /scratch/gilbreth/patil185/artifacts/models/model_autoencoder
progress_description = ModelAutoEncoder
