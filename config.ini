[extractor]
output_stack_size = 8192
model_output_folder = /scratch/gautschi/patil185/artifacts/extracted/models
default_extractor_class = HuggingFacePipelineExtractor
extractor_registry = {
    "Fashion-Mnist-SigLIP2": "SiglipExtractor",
    "Mnist-Digits-SigLIP2": "SiglipExtractor",
    "resnet34_svhn": "DetectorBasedExtractor",
    "densenet121_svhn": "DetectorBasedExtractor",
    "vgg16_bn_svhn": "DetectorBasedExtractor",
    "resnet34_cifar100": "DetectorBasedExtractor",
    "resnet18_cifar100": "DetectorBasedExtractor",
    }

[autoencoder]
; A single linear layer is often enough for very small datasets; add more depth for complex parameter spaces.
encoder_input_size = 8192
encoder_output_size = 512
decoder_output_size = 8192
encoder_hidden_layers = [1024]
decoder_hidden_layers = [1024]
use_activation = true
dropout = 0.05
activation = gelu

[train_model_autoencoder]
batch_size = 16
num_epochs = 3
num_workers = 12
device = cuda
learning_rate = 0.001
shuffle = true
log_every_n_epochs = 5
extracted_models_dir = /scratch/gautschi/patil185/artifacts/extracted/models
model_save_directory = /scratch/gautschi/patil185/artifacts/models/model_autoencoder
progress_description = ModelAutoEncoder
weight_decay = 0.0001
beta1 = 0.9
beta2 = 0.999
gradient_clip_norm = 1.0
early_stopping_patience = 40
early_stopping_min_delta = 0.0001
scheduler_factor = 0.5
scheduler_patience = 15
scheduler_min_lr = 0.00001
normalize_inputs = true
code_l1_penalty = 0.001
reconstruction_loss = smooth_l1
smooth_l1_beta = 0.5

[dataset_defaults]
cache_dir = /scratch/gautschi/patil185/artifacts/data
split_ratios = [0.8, 0.1, 0.1]
seed = 42
drop_last = false
shuffle = false
num_workers = 4
pin_memory = true
persistent_workers = true
prefetch_factor = 2
image_column = image
label_column = label
balance_classes = true
max_samples_train = 131072
max_samples_validation = 8192
max_samples_test = 65536

[clip_evaluation]
model_name = openai/clip-vit-base-patch32
device = cuda
precision = fp16
normalize_features = true
output_directory = /scratch/gautschi/patil185/artifacts/extracted/datasets
batches_per_shard = 16
cache_directory_override =
pad_to_full_shard = true
; dataset_names = ["MNIST", "SVHN", "USPS Digits", "Fashion-MNIST", "Deepfashion Inshop", "Fashion Product", "ImageNet 1k", "CIFAR-10", "CIFAR-100", "Caltech-101", "HAM10000", "LIDC-IDRI", "BCW"]
dataset_names = ["USPS Digits"]
limit_batches_per_split = None
extra_load_kwargs = {}

[dataset_loader]
default_loader_class = GenericBalancedDataLoader
loader_registry = {
    "MNIST": {"dataset_name": "ylecun/mnist"},
    "SVHN": {"dataset_name": "ufldl-stanford/svhn", "dataset_config": "cropped_digits"},
    "USPS Digits": {"dataset_name": "Voxel51/USPS"},
    "Fashion-MNIST": {"dataset_name": "zalando-datasets/fashion_mnist"},
    "Deepfashion Inshop": {"dataset_name": "Marqo/deepfashion-inshop", "label_column": "category2"},
    "Fashion Product": {"dataset_name": "ashraq/fashion-product-images-small", "label_column": "usage"},
    "ImageNet 1k": {"dataset_name": "ILSVRC/imagenet-1k"},
    "CIFAR-10": {"dataset_name": "uoft-cs/cifar10", "image_column": "img", "label_column": "label"},
    "CIFAR-100": {"dataset_name": "uoft-cs/cifar100", "image_column": "img", "label_column": "fine_label"},
    "Caltech-101": {
        "dataset_name": "bitmind/caltech-101",
        "label_from_filename": {"source_column": "filename", "target_column": "label", "separator": "/", "index": 0, "strip_extension": True, "lowercase": True},
        "label_column": "label"
    },
    "HAM10000": {"dataset_name": "Nagabu/HAM10000"},
    "LIDC-IDRI": {"dataset_name": "jmanuelc87/lidc-idri-segmentation"},
    "BCW": {"dataset_name": "scikit-learn/breast-cancer-wisconsin"}
    }

[autoencoder_evaluation]
weights_path = /scratch/gautschi/patil185/artifacts/models/model_autoencoder/autoencoder_weights.loss_0.008648.20251103_085137.pt
parameter_root = /scratch/gautschi/patil185/artifacts/extracted/models
output_directory = /scratch/gautschi/patil185/artifacts/extracted/model_embeddings
batch_size = 256
device = cuda
normalize_inputs = true
flatten = true
input_dtype = float32
file_substring = ""
save_dtype = float32

[model_embedding_loader]
root_dir = /scratch/gautschi/patil185/artifacts/extracted/model_embeddings
embedding_key = embedding
batch_size = 16
max_models = 16
shuffle = true
num_workers = 0
pin_memory = true

[dataset_token_loader]
root_dir = /scratch/gautschi/patil185/artifacts/extracted/datasets
dataset_names = None
splits = ["train", "validation", "test"]
shard_glob = "*.npz"
batch_size = 16
shuffle = true
include_class_metadata = true
num_workers = 0
pin_memory = true

[similarity_model]
embedding_dim = 512
hidden_dim = 768
num_models = 16
transformer_layers = 16
transformer_heads = 8
intermediate_dim = 2048
dropout = 0.05
attention_dropout = 0.05
classifier_dropout = 0.05
max_position_embeddings = 4096
use_pretrained = false
pretrained_model_name = None
temperature_init = 0.07
temperature_min = 0.01
temperature_max = 5.0

[train_similarity_transformer]
batch_size = 16
num_epochs = 150
learning_rate = 0.001
weight_decay = 0.0001
gradient_clip_norm = 1.0
shuffle = true
log_every_n_epochs = 1
log_every_n_steps = 100
early_stopping_patience = 20
early_stopping_min_delta = 0.0001
scheduler_factor = 0.5
scheduler_patience = 10
scheduler_min_lr = 0.00001
scheduler_threshold = 0.0001
scheduler_threshold_mode = rel
scheduler_mode = min
validation_splits = ["validation"]
validation_interval_epochs = 1
label_smoothing = 0.1
temperature_init = 0.07
temperature_min = 0.01
temperature_max = 5.0
hard_negative_top_k = 4
hard_negative_margin = 0.05
hard_negative_weight = 0.3
overfit_subset_size = 64
overfit_max_epochs = 50
overfit_shuffle = true
enable_overfit_check = true
log_grad_stats = true
log_activation_stats = true
ranking_loss_weight = 0.1
logit_l2_weight = 0.0001
extra_loss_weight = 0.0
model_save_directory = /scratch/gautschi/patil185/artifacts/models/similarity_transformer

[custom_similarity_transformer]
; Cross-attention based model selector for ranking models given dataset features
; embed_dim: Embedding dimension for Q, K, V projections (must match input embeddings)
; num_heads: Number of attention heads for multi-head attention
; num_layers: Number of stacked cross-attention layers
; dropout: Dropout rate applied in attention layers
embed_dim = 512
num_heads = 8
num_layers = 2
dropout = 0.1
batch_first = true

[custom_similarity_transformer_trainer]
; Training configuration for CustomSimilarityTransformer model
; Combines ranking loss and L2 regularization
batch_size = 32
num_epochs = 100
learning_rate = 0.0001
weight_decay = 0.001
regularization_weight = 0.1
shuffle = true
gradient_clip_norm = 1.0
early_stopping_patience = 10
early_stopping_min_delta = 0.0001
scheduler_factor = 0.5
scheduler_patience = 5
scheduler_min_lr = 0.000001
validation_interval_epochs = 1
log_every_n_epochs = 1
progress_description = CustomSimilarityTransformer
seed = 42
model_save_directory = /scratch/gautschi/patil185/artifacts/models/custom_similarity_transformer
